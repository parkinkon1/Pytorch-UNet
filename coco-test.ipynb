{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import splitext\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class BasicDataset(Dataset):\n",
    "    def __init__(self, imgs_dir, masks_dir, scale=1):\n",
    "        self.imgs_dir = imgs_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.scale = scale\n",
    "        assert 0 < scale <= 1, 'Scale must be between 0 and 1'\n",
    "\n",
    "        self.ids = [splitext(file)[0] for file in listdir(imgs_dir)\n",
    "                    if not file.startswith('.')]\n",
    "        logging.info(f'Creating dataset with {len(self.ids)} examples')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess(cls, pil_img, scale):\n",
    "        w, h = pil_img.size\n",
    "        newW, newH = int(scale * w), int(scale * h)\n",
    "        assert newW > 0 and newH > 0, 'Scale is too small'\n",
    "        pil_img = pil_img.resize((newW, newH))\n",
    "\n",
    "        img_nd = np.array(pil_img)\n",
    "\n",
    "        if len(img_nd.shape) == 2:\n",
    "            img_nd = np.expand_dims(img_nd, axis=2)\n",
    "\n",
    "        # HWC to CHW\n",
    "        img_trans = img_nd.transpose((2, 0, 1))\n",
    "        if img_trans.max() > 1:\n",
    "            img_trans = img_trans / 255\n",
    "\n",
    "        return img_trans\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.ids[i]\n",
    "        mask_file = glob(self.masks_dir + idx + '*')\n",
    "        img_file = glob(self.imgs_dir + idx + '*')\n",
    "\n",
    "        assert len(mask_file) == 1, \\\n",
    "            f'Either no mask or multiple masks found for the ID {idx}: {mask_file}'\n",
    "        assert len(img_file) == 1, \\\n",
    "            f'Either no image or multiple images found for the ID {idx}: {img_file}'\n",
    "        mask = Image.open(mask_file[0])\n",
    "        img = Image.open(img_file[0])\n",
    "\n",
    "        assert img.size == mask.size, \\\n",
    "            f'Image and mask {idx} should be the same size, but are {img.size} and {mask.size}'\n",
    "\n",
    "        img = self.preprocess(img, self.scale)\n",
    "        mask = self.preprocess(mask, self.scale)\n",
    "\n",
    "        return {'image': torch.from_numpy(img), 'mask': torch.from_numpy(mask)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from eval import eval_net\n",
    "from unet import UNet\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.dataset import BasicDataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "dir_img = 'data/imgs/'\n",
    "dir_mask = 'data/masks/'\n",
    "dir_checkpoint = 'checkpoints/'\n",
    "\n",
    "\n",
    "def train_net(net,\n",
    "              device,\n",
    "              epochs=5,\n",
    "              batch_size=1,\n",
    "              lr=0.001,\n",
    "              val_percent=0.1,\n",
    "              save_cp=True,\n",
    "              img_scale=0.5):\n",
    "\n",
    "    dataset = BasicDataset(dir_img, dir_mask, img_scale)\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    train, val = random_split(dataset, [n_train, n_val])\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=True)\n",
    "\n",
    "    writer = SummaryWriter(comment=f'LR_{lr}_BS_{batch_size}_SCALE_{img_scale}')\n",
    "    global_step = 0\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {lr}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_cp}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "    ''')\n",
    "\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min' if net.n_classes > 1 else 'max', patience=2)\n",
    "    if net.n_classes > 1:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                imgs = batch['image']\n",
    "                true_masks = batch['mask']\n",
    "                assert imgs.shape[1] == net.n_channels, \\\n",
    "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {imgs.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "                mask_type = torch.float32 if net.n_classes == 1 else torch.long\n",
    "                true_masks = true_masks.to(device=device, dtype=mask_type)\n",
    "\n",
    "                masks_pred = net(imgs)\n",
    "                loss = criterion(masks_pred, true_masks)\n",
    "                epoch_loss += loss.item()\n",
    "                writer.add_scalar('Loss/train', loss.item(), global_step)\n",
    "\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_value_(net.parameters(), 0.1)\n",
    "                optimizer.step()\n",
    "\n",
    "                pbar.update(imgs.shape[0])\n",
    "                global_step += 1\n",
    "                if global_step % (len(dataset) // (10 * batch_size)) == 0:\n",
    "                    for tag, value in net.named_parameters():\n",
    "                        tag = tag.replace('.', '/')\n",
    "                        writer.add_histogram('weights/' + tag, value.data.cpu().numpy(), global_step)\n",
    "                        writer.add_histogram('grads/' + tag, value.grad.data.cpu().numpy(), global_step)\n",
    "                    val_score = eval_net(net, val_loader, device)\n",
    "                    scheduler.step(val_score)\n",
    "                    writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], global_step)\n",
    "\n",
    "                    if net.n_classes > 1:\n",
    "                        logging.info('Validation cross entropy: {}'.format(val_score))\n",
    "                        writer.add_scalar('Loss/test', val_score, global_step)\n",
    "                    else:\n",
    "                        logging.info('Validation Dice Coeff: {}'.format(val_score))\n",
    "                        writer.add_scalar('Dice/test', val_score, global_step)\n",
    "\n",
    "                    writer.add_images('images', imgs, global_step)\n",
    "                    if net.n_classes == 1:\n",
    "                        writer.add_images('masks/true', true_masks, global_step)\n",
    "                        writer.add_images('masks/pred', torch.sigmoid(masks_pred) > 0.5, global_step)\n",
    "\n",
    "        if save_cp:\n",
    "            try:\n",
    "                os.mkdir(dir_checkpoint)\n",
    "                logging.info('Created checkpoint directory')\n",
    "            except OSError:\n",
    "                pass\n",
    "            torch.save(net.state_dict(),\n",
    "                       dir_checkpoint + f'CP_epoch{epoch + 1}.pth')\n",
    "            logging.info(f'Checkpoint {epoch + 1} saved !')\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks',\n",
    "                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('-e', '--epochs', metavar='E', type=int, default=5,\n",
    "                        help='Number of epochs', dest='epochs')\n",
    "    parser.add_argument('-b', '--batch-size', metavar='B', type=int, nargs='?', default=1,\n",
    "                        help='Batch size', dest='batchsize')\n",
    "    parser.add_argument('-l', '--learning-rate', metavar='LR', type=float, nargs='?', default=0.1,\n",
    "                        help='Learning rate', dest='lr')\n",
    "    parser.add_argument('-f', '--load', dest='load', type=str, default=False,\n",
    "                        help='Load model from a .pth file')\n",
    "    parser.add_argument('-s', '--scale', dest='scale', type=float, default=0.5,\n",
    "                        help='Downscaling factor of the images')\n",
    "    parser.add_argument('-v', '--validation', dest='val', type=float, default=10.0,\n",
    "                        help='Percent of the data that is used as validation (0-100)')\n",
    "\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "args = get_args()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "# Change here to adapt to your data\n",
    "# n_channels=3 for RGB images\n",
    "# n_classes is the number of probabilities you want to get per pixel\n",
    "#   - For 1 class and background, use n_classes=1\n",
    "#   - For 2 classes, use n_classes=1\n",
    "#   - For N > 2 classes, use n_classes=N\n",
    "net = UNet(n_channels=3, n_classes=1, bilinear=True)\n",
    "logging.info(f'Network:\\n'\n",
    "             f'\\t{net.n_channels} input channels\\n'\n",
    "             f'\\t{net.n_classes} output channels (classes)\\n'\n",
    "             f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')\n",
    "\n",
    "if args.load:\n",
    "    net.load_state_dict(\n",
    "        torch.load(args.load, map_location=device)\n",
    "    )\n",
    "    logging.info(f'Model loaded from {args.load}')\n",
    "\n",
    "net.to(device=device)\n",
    "# faster convolutions, but more memory\n",
    "# cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_img = 'data/imgs/'\n",
    "dir_mask = 'data/masks/'\n",
    "dir_checkpoint = 'checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "batch_size=1\n",
    "lr=0.001\n",
    "val_percent=0.1\n",
    "save_cp=True\n",
    "img_scale=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-519d78a8c164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m---> 94\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "dataset = BasicDataset(dir_img, dir_mask, img_scale)\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train, val = random_split(dataset, [n_train, n_val])\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=True)\n",
    "\n",
    "writer = SummaryWriter(comment=f'LR_{lr}_BS_{batch_size}_SCALE_{img_scale}')\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "COCOAPI_PATH = '/Users/parkkyuyeol/Desktop/DGIST_intern/cocoapi/PythonAPI'\n",
    "sys.path.append(COCOAPI_PATH)\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='/Users/parkkyuyeol/Desktop/DGIST_intern/cocodataset'\n",
    "dataType='val2017'\n",
    "annFile='{}/annotations/instances_{}.json'.format(dataDir,dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.54s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# initialize COCO api for instance annotations\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO categories: \n",
      "person bicycle car motorcycle airplane bus train truck boat traffic light fire hydrant stop sign parking meter bench bird cat dog horse sheep cow elephant bear zebra giraffe backpack umbrella handbag tie suitcase frisbee skis snowboard sports ball kite baseball bat baseball glove skateboard surfboard tennis racket bottle wine glass cup fork knife spoon bowl banana apple sandwich orange broccoli carrot hot dog pizza donut cake chair couch potted plant bed dining table toilet tv laptop mouse remote keyboard cell phone microwave oven toaster sink refrigerator book clock vase scissors teddy bear hair drier toothbrush\n",
      "\n",
      "COCO supercategories: \n",
      "person vehicle appliance indoor furniture animal sports accessory food kitchen outdoor electronic\n"
     ]
    }
   ],
   "source": [
    "# display COCO categories and supercategories\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "nms=[cat['name'] for cat in cats]\n",
    "print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
    "\n",
    "nms = set([cat['supercategory'] for cat in cats])\n",
    "print('COCO supercategories: \\n{}'.format(' '.join(nms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'supercategory': 'person', 'id': 1, 'name': 'person'},\n",
       " {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'},\n",
       " {'supercategory': 'vehicle', 'id': 3, 'name': 'car'},\n",
       " {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'},\n",
       " {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'},\n",
       " {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'},\n",
       " {'supercategory': 'vehicle', 'id': 7, 'name': 'train'},\n",
       " {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'},\n",
       " {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'},\n",
       " {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'},\n",
       " {'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'},\n",
       " {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'},\n",
       " {'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'},\n",
       " {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'},\n",
       " {'supercategory': 'animal', 'id': 16, 'name': 'bird'},\n",
       " {'supercategory': 'animal', 'id': 17, 'name': 'cat'},\n",
       " {'supercategory': 'animal', 'id': 18, 'name': 'dog'},\n",
       " {'supercategory': 'animal', 'id': 19, 'name': 'horse'},\n",
       " {'supercategory': 'animal', 'id': 20, 'name': 'sheep'},\n",
       " {'supercategory': 'animal', 'id': 21, 'name': 'cow'},\n",
       " {'supercategory': 'animal', 'id': 22, 'name': 'elephant'},\n",
       " {'supercategory': 'animal', 'id': 23, 'name': 'bear'},\n",
       " {'supercategory': 'animal', 'id': 24, 'name': 'zebra'},\n",
       " {'supercategory': 'animal', 'id': 25, 'name': 'giraffe'},\n",
       " {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'},\n",
       " {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'},\n",
       " {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'},\n",
       " {'supercategory': 'accessory', 'id': 32, 'name': 'tie'},\n",
       " {'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'},\n",
       " {'supercategory': 'sports', 'id': 34, 'name': 'frisbee'},\n",
       " {'supercategory': 'sports', 'id': 35, 'name': 'skis'},\n",
       " {'supercategory': 'sports', 'id': 36, 'name': 'snowboard'},\n",
       " {'supercategory': 'sports', 'id': 37, 'name': 'sports ball'},\n",
       " {'supercategory': 'sports', 'id': 38, 'name': 'kite'},\n",
       " {'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'},\n",
       " {'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'},\n",
       " {'supercategory': 'sports', 'id': 41, 'name': 'skateboard'},\n",
       " {'supercategory': 'sports', 'id': 42, 'name': 'surfboard'},\n",
       " {'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'},\n",
       " {'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'},\n",
       " {'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'},\n",
       " {'supercategory': 'kitchen', 'id': 47, 'name': 'cup'},\n",
       " {'supercategory': 'kitchen', 'id': 48, 'name': 'fork'},\n",
       " {'supercategory': 'kitchen', 'id': 49, 'name': 'knife'},\n",
       " {'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'},\n",
       " {'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'},\n",
       " {'supercategory': 'food', 'id': 52, 'name': 'banana'},\n",
       " {'supercategory': 'food', 'id': 53, 'name': 'apple'},\n",
       " {'supercategory': 'food', 'id': 54, 'name': 'sandwich'},\n",
       " {'supercategory': 'food', 'id': 55, 'name': 'orange'},\n",
       " {'supercategory': 'food', 'id': 56, 'name': 'broccoli'},\n",
       " {'supercategory': 'food', 'id': 57, 'name': 'carrot'},\n",
       " {'supercategory': 'food', 'id': 58, 'name': 'hot dog'},\n",
       " {'supercategory': 'food', 'id': 59, 'name': 'pizza'},\n",
       " {'supercategory': 'food', 'id': 60, 'name': 'donut'},\n",
       " {'supercategory': 'food', 'id': 61, 'name': 'cake'},\n",
       " {'supercategory': 'furniture', 'id': 62, 'name': 'chair'},\n",
       " {'supercategory': 'furniture', 'id': 63, 'name': 'couch'},\n",
       " {'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'},\n",
       " {'supercategory': 'furniture', 'id': 65, 'name': 'bed'},\n",
       " {'supercategory': 'furniture', 'id': 67, 'name': 'dining table'},\n",
       " {'supercategory': 'furniture', 'id': 70, 'name': 'toilet'},\n",
       " {'supercategory': 'electronic', 'id': 72, 'name': 'tv'},\n",
       " {'supercategory': 'electronic', 'id': 73, 'name': 'laptop'},\n",
       " {'supercategory': 'electronic', 'id': 74, 'name': 'mouse'},\n",
       " {'supercategory': 'electronic', 'id': 75, 'name': 'remote'},\n",
       " {'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'},\n",
       " {'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'},\n",
       " {'supercategory': 'appliance', 'id': 78, 'name': 'microwave'},\n",
       " {'supercategory': 'appliance', 'id': 79, 'name': 'oven'},\n",
       " {'supercategory': 'appliance', 'id': 80, 'name': 'toaster'},\n",
       " {'supercategory': 'appliance', 'id': 81, 'name': 'sink'},\n",
       " {'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'},\n",
       " {'supercategory': 'indoor', 'id': 84, 'name': 'book'},\n",
       " {'supercategory': 'indoor', 'id': 85, 'name': 'clock'},\n",
       " {'supercategory': 'indoor', 'id': 86, 'name': 'vase'},\n",
       " {'supercategory': 'indoor', 'id': 87, 'name': 'scissors'},\n",
       " {'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'},\n",
       " {'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'},\n",
       " {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda3_pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
